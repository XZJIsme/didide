# 保护地得，从我做起
Didide 是基于 BERT 预训练模型进行微调的“的地得”纠错模型，训练数据使用维基百科中文语料库生成。
# Sir, this way
Didide is a model for correcting 的, 地, 得 based on BERT. The training data is generated from the Chinese Wikipedia corpus.
## Get started now
```bash
conda create -n huggingface python=3.10 -y
conda activate huggingface
conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch -y
pip install transformers datasets
```
## Convert a TensorFlow pre-trained BERT model to PyTorch
```bash
conda install tensorflow -y
mkdir BERT-trained
cd BERT-trained
wget https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip
unzip chinese_L-12_H-768_A-12.zip
cd ..
python bert_converter.py
# of course, you can also use the default chinese bert model provided by huggingface which may be better
```
## Generate DidideData
```python
# python dataset_generator.py
"""
Here we use wiki_zh from https://github.com/brightmart/nlp_chinese_corpus
A sample of processed wiki_zh data is in data/samples, named wiki_zh_mini.pkl which contains a list generated by the script.
"""
# for file in glob.glob("yourcorpus/**", recursive=True):
# ↑if you use customized corpus, some modifications are needed, see the easy-to-read script for details.
for file in glob.glob("data/wiki_zh/**", recursive=True):
    if os.path.isdir(file):
        continue
    files.append(file)
# Total samples:  311569
# 的：122867，地：129195，得：59507
"""
To get a better distribution, the number of 的 is reduced.
"""
```
## Train the model
```bash
python model_training.py
# with a good hyperparameter setting, just a few epochs needed to obtain a good accuracy on test set like about 96%.
```
## Trained models
[百度网盘](https://pan.baidu.com/s/1jlt3Nzjr6kUGn58N9tSErg?pwd=ddde)

## Give it a try
```bash
python playground.py "我觉的我烦的有点难过，因为我得培根忘记吃了" "didide_model.pt"
# the output'd be: 我觉得我烦得有点难过，因为我的培根忘记吃了
python playground.py "我觉的我烦的有点难过，因为我得培根忘记吃了，而且这种东西得营养一般般，但是好吃的哟！我天天早上开心的享受它的味道，开心的受不鸟了" "didide_model.pt"
# the output'd be: 我觉得我烦得有点难过，因为我的培根忘记吃了，而且这种东西的营养一般般，但是好吃的哟！我天天早上开心地享受它的味道，开心得受不鸟了
```
## In the last
本项目仅供学习交流，如有问题请提 issue ！有什么好建议请随时提 issue ！

Also, welcome to contribute to this project! A trained model will be released soon.
## ToDo
- ~~Add a trained model~~ ✔
- The way of generating test dataset should match the way of the playground, different from the way of training data generation, then the robustness of the model can be tested more reasonably.
- Give a lightweigth model by quantization.
- Give an elaborate instroduction in Chinese. 是中国人就说你好！
- 试试 multilingual pre-trained model
## Reference
- [NLP Chinese Corpus](https://github.com/brightmart/nlp_chinese_corpus)
- [Hugging Face](https://huggingface.co/transformers/quicktour.html)
